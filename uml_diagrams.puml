@startuml LLM_Disco_Class_Diagram
title LLM Disco - Class Diagram

skinparam classAttributeIconSize 0

package "Models" {
  class ChatMessage {
    + role : String
    + content : String
    + timestamp : DateTime
    + images : List<String>?
    + thinking : String?
    --
    + toJson() : Map
    + toApiMap() : Map
  }

  class Conversation {
    + id : String
    + title : String
    + model : String
    + messages : List<ChatMessage>
    + thinkingEnabled : bool
    + webSearchEnabled : bool
    --
    + toJson() : Map
  }

  Conversation "1" *-- "0..*" ChatMessage
}

package "Services" {
  class OllamaService {
    + baseUrl : String
    --
    + streamChat(model, messages) : Stream
    + fetchModels() : Future<List<String>>
    + testConnection() : Future<void>
    + cancelStream() : void
  }

  class StorageService {
    --
    + loadConversations() : Future<List<Conversation>>
    + saveConversations(list) : Future<void>
    + loadConnectionSettings() : Future<Map?>
    + saveConnectionSettings(...) : Future<void>
  }
}

package "Providers" {
  class ConnectionProvider {
    + service : OllamaService?
    + isConnected : bool
    + error : String?
    --
    + connect(ip, port) : Future<void>
    + disconnect() : void
  }

  class ChatProvider {
    + conversations : List<Conversation>
    + activeConversation : Conversation?
    + isStreaming : bool
    --
    + createConversation(model) : void
    + sendMessage(content) : Future<void>
    + stopStreaming() : void
    + deleteConversation(id) : void
  }

  class ModelProvider {
    + models : List<String>
    + selectedModel : String?
    --
    + fetchModels(service) : Future<void>
    + selectModel(model) : void
  }

  ConnectionProvider "1" --> "0..1" OllamaService : creates
  ChatProvider "1" --> "0..1" OllamaService : uses
  ChatProvider "1" --> "0..1" StorageService : saves via
  ChatProvider "1" --> "0..*" Conversation : manages
  ModelProvider "1" --> "0..1" OllamaService : uses
}

package "Screens" {
  class ConnectionScreen
  class ChatListScreen
  class ChatScreen

  ConnectionScreen ..> ConnectionProvider : reads/writes
  ConnectionScreen ..> ModelProvider : fetches models
  ChatListScreen ..> ChatProvider : reads
  ChatListScreen ..> ModelProvider : reads
  ChatScreen ..> ChatProvider : reads/writes
  ChatScreen ..> ModelProvider : reads capabilities
}

@enduml


@startuml LLM_Disco_Navigation
title LLM Disco - Screen Navigation

[*] --> ConnectionScreen : App Launch

ConnectionScreen --> ChatListScreen : Connect Success
ChatListScreen --> ConnectionScreen : Disconnect
ChatListScreen --> ChatScreen : Tap / New Chat
ChatScreen --> ChatListScreen : Back

@enduml


@startuml LLM_Disco_SendMessage_Sequence
title LLM Disco - Send Message

actor User
participant ChatScreen
participant ChatProvider
participant OllamaService
participant "Ollama Server" as Ollama

User -> ChatScreen : type & tap Send
ChatScreen -> ChatProvider : sendMessage(content)
ChatProvider -> ChatProvider : add user message\nto conversation
ChatProvider -> OllamaService : streamChat(model, messages)
OllamaService -> Ollama : POST /api/chat

loop streaming
  Ollama --> OllamaService : JSON chunk
  OllamaService --> ChatProvider : token
  ChatProvider -> ChatProvider : append to\nassistant message
  ChatProvider --> ChatScreen : notifyListeners()
end

Ollama --> OllamaService : done: true
ChatProvider -> ChatProvider : save to storage

@enduml
